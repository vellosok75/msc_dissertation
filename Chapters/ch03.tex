\chapter{Online Optimization}
This chapter defines online optimization in the context of accelerators. An overview of optimzation algorithms and their classifications is presented. The Robust Conjugate Direction Search algorithm is introduced and some of its applications in the accelerator community are discussed.
\section{Defining Online Optimzation}
Suppose we have a machine in which there is some sort of figure of merit depending on the collective state of relevent components, parts or operation mode. There is no mechanistic, deterministic or probabolistic model for the dependence of the figure of merit based on the relevant components state, but we do know these parameters have effect over our figure of merit. We might as well call these relevant parameters our knobs, since we can use them to tune the figure of merit. The whole system is a black-box. To access diferent values for the figure of merit, i.e., to sample it, we need to change the knobs, and measure the figure of merit.

Now suppose we want to tune the knobs so the figure of merit reches a certain value, or so that it is minimized or maximized. This is an optimization problem, and we might as well call the figure of merit our objective function. If we are able to devise a computer-automated strategy to seek for the desired value or extremum of the objective function, then running this program while the machine is up and working is what we define as online optimization.

The program must read the objective function and current state of the knobs, calculate the desired changes on the knobs, perform the changes evaluate the objective and repeat this process until reaching the desired outcome.

This is exactly where we are when it comes to the Dynamic Aperture. It is a figure of merit related to the nonlinear dynamics, in our case the sextupole magnets. There is no analytical/statistical\footnote{in principle, a surrogate model could be trained to reproduce dynamic aperture given the sextupole strengths as inputs. This is not what we have done so far} model prediciting DA changes given sextupole nudges so we cannot invert the problem and tune sextupoles to the desired DA value. Therefore, online otpimzation fits this problem well.

\section{Robust Conjugate Direction Search}
In the literature, optimization routines and algorithms are usually classified according to whether they rely on the calculation of derivatives (gradient-based) or solely on the comparison of the objective function values (gradient-free). The latter can yet be classified into direct- or indirect-search methods, depending on whether the search of the extremum relies on direct comparisons of the objective function itself or from a mathematical model of it, respectively \cite{numerical_recipes}.

Both gradient-based and gradient-free strategies rely on the comparison of the objective function at different points of the parameter space. If the objective function suffers from noise this can significantly reduce the efficiency of the optimization routine \cite{numerical_recipes, huang2019beam}. In Chap. 7 of Ref.~\cite{huang2019beam}, a review of the most popular optimization algorithms shows how most of them suffer to find minima to, at least, the precision of the noise-$\sigma$ the objective function is subjected to.

The Robust Conjugate Direction Search (RCDS) algorithm is a indirect-search, gradient-free optimization algorithm introduced in Ref.~\cite{Huang:2013}. The algorithm consists of a main loop for constructing and managing optimal search directions along the knobs space (Powell's Method) and a one-dimensional optimizer responsible for a noise-aware search for the minimum along a given direction. The algorithm is capable of optimizing the objective function (find its local maximum/minimum) to at least the precision of the objective-function noise \cite{Huang:2013, huang2019beam}, being thus adequate for online optimization problems. Specifically, for accelerator controls and optimization, the algorithm has been successfully applied to optimize beam steering and optics matching during injection \cite{Huang:2013}, reducing horizontal emittance \cite{Huang:2013, Huang:2015}and optimization of dynamic aperture \cite{Huang:2013,Huang:2015,Liuzzo:IPAC2016-THPMR015,Olsson:IPAC2018-WEPAL047,yang:ipac2022-tupopt064}.
\subsection{Line methods}
Let $f(x)\in\mathbb{R}$ be the objective function depending on the single parameter $x\in\mathbb{R}$. The task of optimizing (minimizing or maximizing) $f$ can be achieved by a direct search onver the possibile values of $x$. Since maximizing a function equals to minimizing the same function multipled by $-1$, in what follows, we shall refer to minimization only.

The search for the minimum is usually preceeded by initially \textit{bracketing} the miminum: finding a triplet of points $a<b<c$ in the domain such that $f(b)$ is smaller than both $f(a)$ and $f(c)$. If $f$ is reasonably smooth, we are certain there will be a minimium in the interval $(a, c)$. Standard bracket routines for well-behaved, noiseless objective functions can be found in the literature.

Given an intial bracketed interval, the most common line-search methods are
\begin{itemize}
    \item Golden Section Search: which updates the brackets progressively shrinking it until spans only a small interval specified by the user. Usually the machine precision is used. The miminum is then found to within this tolerance.
    \item Parabolic Interpolation: where a parabola is fitted to $f(a), f(b), f(c)$. The parabola minimum takes us to the minumum or close to a it in a single leap.
\end{itemize}
For dealing with noisy objective functions, RCDS introduces a noise-aware bracketing routine and a parabolic interpolation scan over the bracket. We assume that what we measure is $y(x)=f(x) + \xi$, where $\xi\sim\mathcal{N}(\mu=0, \sigma)$ is a random variable modeling the experimental noise. Instead of seeking for points $a<b<c$ satisfying $f(b)< f(a), f(b) < f(c)$, RCDS requires a more strict condition $f(b)< f(a)+3\sigma, f(b) < f(c)+3\sigma$, where $\sigma$ is the expected noise $\sigma = \text{Var}[\xi]$.

During the line-search, the parabola is fitted within the brackets and its minimum is taken as the objective function minimum. There is also an additional comparison of the available points within the brackets used for the fitting. If any of them is considered an outlier, it is not used during the fitting.
\subsection{Powell's conjugate direction set}
With a line-optimizer at hand, optimization of the objective function $f(\vb{x})\in\mathbb{R}$ depending on $p$ parameters $x_i$ (knobs) arranged as $\vb{x} = \mqty[x_1 & \dots & x_p]^\intercal \in \mathbb{R}^p$ is a simple matter of iterating the one-dimensional minimization along the direction of each one of the $p$ unit vectors $\vu{e}_i$. That is, given an intial configuration $\vb{x}_0$, and directions $\vu{n}$, we have the one-dimensional problem to minimize $g(\delta)=f(\vb{x}_0 + \delta \vu{n})$. The minimum is  then $f(\vb{x}_0 + \delta_* \vu{n})$, where $\delta_* = \text{arg min}_\delta g(\delta)$

As can be seen in figure, scanning along each orthogonal directioon can be time consuming and suboptimial when evaluation of the objective function is expensive, specially for some functions with long narrow valleys at some angle with the coordinates basis vectors.

A more effieicent strategy was introduced by Powell, which advises the construction of mutually conjugate directions. Powell proves these are non-iterfering directions, meaning the minimization carried at any given conjugate direction does not spoil the minimiation along any other of them.

Conjugate directions are constructed as follows
\begin{enumerate}
    \item Set the initial directions as the basis vectors: $\vu{u}_i=\vu{e}_i, i=1,\dots, p$.
    \item Save the starting point (initial parameters state) as $\vb{x}_0$ and let $\vb{x}_i$ denote the minimum position found up until the minimization along the $i$th direction.
    \item For $i=1,\dots, p$ minimize along $\vu{u}_i$. Update the minimimum $\vb{x}_i$.
    \item For $i=1,\dots p-1$ set $\vu{u}_i\to\vu{u}_{i+1}$
    \item Set $\vb{u}_p=\vb{x}_p - \vb{x}_0$. Normalize to obtain $\vu{u}_p$.
    \item Minimize along $\vu{u}_p$. Call the minimum found $\vb{x}_0$ and repeat the procedure until reaching a certain number of evaluations or until some condition is reached.
\end{enumerate}
